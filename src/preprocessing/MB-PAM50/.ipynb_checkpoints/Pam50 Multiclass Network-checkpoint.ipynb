{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "sys.path.append('C:/Users/sumaiyah/OneDrive - University Of Cambridge/Project/NN-Builder/src/preprocessing/MB-PAM50')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import get_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multiclassification Network for Pam50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns train or test data from a specific fold\n",
    "get_data_from_fold = lambda data_type, fold_index: pd.read_csv('5-fold_pam50stratified/fold%s/MBdata_33CLINwMiss_1KfGE_1KfCNA_%s.csv' % (str(fold_index), data_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_col = 'pam50np'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\sumaiyah\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3249: DtypeWarning: Columns (19,20) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  if (await self.run_code(code, result,  async_=asy)):\n"
     ]
    }
   ],
   "source": [
    "train_data = get_data(get_data_from_fold('train', 1))\n",
    "test_data = get_data(get_data_from_fold('test', 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'0': 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "for col in pd.DataFrame(train_data['pam50np']).columns:\n",
    "    print(Counter(train_data['pam50np'][col]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Concatenate gene expression data and clinical data for input to pam50\n",
    "train_data_df = pd.concat([pd.DataFrame(train_data['rnanp']),pd.DataFrame(train_data['clin'])], axis=1, ignore_index=True)\n",
    "train_data_df['target'] = train_data[target_col]\n",
    "train_data_df = remove_any_rows_with_unknowns(train_data_df)\n",
    "train_data_df.to_csv('train_data.csv', index=False)\n",
    "\n",
    "test_data_df = pd.concat([pd.DataFrame(test_data['rnanp']),pd.DataFrame(test_data['clin'])], axis=1, ignore_index=True)\n",
    "test_data_df['target'] = test_data[target_col]\n",
    "test_data_df.to_csv('test_data.csv', index=False)\n",
    "\n",
    "print(train_data_df.shape)\n",
    "print(test_data_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import Dense\n",
    "\n",
    "def build_network(structure: List[int], activation_function: str, loss='categorical_crossentropy', optimizer='adam'):\n",
    "    # Assuming structure is none empty TODO handle case none empty structure\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        structure: structure of network INCLUDING input and output layer\n",
    "        activation_function:\n",
    "        loss:\n",
    "        optimizer:\n",
    "\n",
    "    Returns:\n",
    "        Compiled Keras model based on specification\n",
    "    \"\"\"\n",
    "\n",
    "    # Input layer\n",
    "    input_layer = Input(shape=(structure[0],))\n",
    "\n",
    "    # Hidden Layers\n",
    "    prev_layer = input_layer\n",
    "    for x in range(1, len(structure) - 1):\n",
    "        hidden_layer = Dense(structure[x], activation=activation_function)(prev_layer)\n",
    "        prev_layer = hidden_layer\n",
    "\n",
    "    # Output Layer\n",
    "    output_layer = Dense(structure[len(structure) - 1], activation='softmax')(prev_layer)\n",
    "\n",
    "    # Model input-hidden-output\n",
    "    model = Model(inputs=input_layer, outputs=output_layer)\n",
    "\n",
    "    # Compile Model\n",
    "    model.compile(loss=loss,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = build_network(structure=[1350, 150, 50, 6], activation_function='tanh')\n",
    "batch_size = 25\n",
    "epochs = 200"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_data_df.drop(['target'], axis=1).iloc[:, :].values\n",
    "y_train = train_data_df['target'].values\n",
    "\n",
    "X_test = test_data_df.drop(['target'], axis=1).iloc[:, :].values\n",
    "y_test = test_data_df['target'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# Weight classes due to imbalanced dataset\n",
    "class_weights = dict(enumerate(class_weight.compute_class_weight('balanced', np.unique(y_train), y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "model.fit(X_train,\n",
    "          to_categorical(y_train),\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          verbose=0,\n",
    "          class_weight=class_weights)\n",
    "\n",
    "# Test Model\n",
    "_, accuracy = model.evaluate(X_test, to_categorical(y_test))\n",
    "\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Model\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save Network Predictions\n",
    "network_predictions = np.argmax(model.predict(X_test), axis=1)\n",
    "with open(('NN_predictions.txt'), 'w') as file:\n",
    "    file.write(' '.join([str(pred) for pred in network_predictions]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# for col in train_data_df.columns:\n",
    "#     print(sum(train_data_df[col]=='?'))\n",
    "#     print(Counter(train_data_df[col]))\n",
    "Counter(train_data_df['target'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
